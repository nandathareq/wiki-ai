Hereâ€™s a professional **README.md** you can use for your project:

---

# ğŸ“š Wikipedia Article Discussor

An interactive **Streamlit web app** that lets you **search, scrape, and discuss Wikipedia articles** using an LLM (via LangChain + Ollama).
The app creates a collaborative "Wikipedia-style discussion" interface where you can ask questions, retrieve reliable knowledge, and navigate between chat and scraped articles.

---

## ğŸš€ Features

* ğŸ” **Search Wikipedia** by keyword in any supported language
* ğŸ“„ **Scrape Wikipedia articles** and store them in a local "directory"
* ğŸ§  **Semantic search** across stored articles using FAISS + embeddings
* ğŸ’¬ **Chat interface** to discuss articles with an AI assistant
* ğŸ“‘ **Article viewer** for reading scraped content in clean format
* ğŸ› ï¸ **Tool-calling system** â€” LLM can decide when to search, scrape, or query articles

---

## ğŸ“‚ Project Structure

```
your_project/
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ app.py                # Main entry (Streamlit app)
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ chat.py           # Chat interface
â”‚   â”‚   â””â”€â”€ article.py        # Article renderer
â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”œâ”€â”€ scraper.py        # Wikipedia scraping + FAISS store
â”‚   â”‚   â””â”€â”€ llm.py            # LLM wrapper + tool orchestration
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ session.py        # Session state initialization (optional)
â”‚
â”‚â”€â”€ tests/                    # Unit tests
â”‚â”€â”€ requirements.txt          # Python dependencies
â”‚â”€â”€ README.md                 # Project documentation
â”‚â”€â”€ .gitignore                # Git ignore rules
```

---

## âš™ï¸ Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/your-username/wikipedia-discuss.git
   cd wikipedia-discuss
   ```

2. Create & activate a virtual environment:

   ```bash
   python -m venv .venv
   source .venv/bin/activate   # Mac/Linux
   .venv\Scripts\activate      # Windows
   ```

3. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

4. (Optional) Download NLTK data:

   ```bash
   python -m nltk.downloader punkt_tab
   ```

---

## â–¶ï¸ Usage

Run the Streamlit app:

```bash
streamlit run src/app.py
```

Then open in your browser:
ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

---

## ğŸ§ª Running Tests

```bash
pytest tests/
```

---

## ğŸ› ï¸ Configuration

You can adjust settings in `config.py` (to be created):

* **LLM model** (default: `qwen2.5:7b`)
* **Embedding model** (default: `nomic-embed-text`)
* **Vector store search parameters**

---

## ğŸ“Œ Example Workflow

1. Start a chat in the **Chat** tab
2. Ask about a topic (e.g., "Tell me about Python programming")
3. The agent may call tools automatically to:

   * Search for a Wikipedia article
   * Scrape the content
   * Store it in the directory
   * Use semantic search to fetch relevant passages
4. View scraped articles in the **Article** tab

---

## ğŸ“„ License

MIT License â€” feel free to use and adapt this project.

---

ğŸ‘‰ Do you want me to also add **screenshots / demo GIF placeholders** in the README so it looks more polished when uploaded to GitHub?
